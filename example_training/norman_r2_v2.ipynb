{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Norman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unreserved 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import copy\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import rapids_singlecell as rsc\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "sys.path.append([REMOVEDFORANONYMITY])\n",
    "import tardis\n",
    "tardis.config = tardis.config_server\n",
    "\n",
    "print(f\"CUDA used: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "_rcparams_path = \"[REMOVEDFORANONYMITY]/figures/rcparams.pickle\"\n",
    "with open(_rcparams_path, 'rb') as file:\n",
    "    _rcparams = pickle.load(file)\n",
    "plt.rcParams.update(_rcparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    adata_file_path = os.path.join(tardis.config.io_directories[\"processed\"], \"cpa_Norman2019_prep_new.h5ad\")\n",
    "    assert os.path.isfile(adata_file_path), f\"File not already exist: `{adata_file_path}`\"\n",
    "    adata = ad.read_h5ad(adata_file_path)\n",
    "    adata.X = adata.layers[\"counts\"].copy()\n",
    "    del adata.layers\n",
    "    gc.collect()\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_epoch_range = [6, 72]\n",
    "\n",
    "counteractive_minibatch_settings = dict(\n",
    "    method = \"categorical_random\",\n",
    "    method_kwargs = dict(\n",
    "        within_labels = False,\n",
    "        within_batch = False,\n",
    "        within_categorical_covs = None,\n",
    "        seed = \"forward\",\n",
    "    )\n",
    ")\n",
    "\n",
    "disentenglement_targets_configurations=[\n",
    "    dict(\n",
    "        obs_key = \"condition\",\n",
    "        n_reserved_latent = 24,\n",
    "        counteractive_minibatch_settings = counteractive_minibatch_settings,\n",
    "        auxillary_losses = [\n",
    "            dict(\n",
    "                apply = True, \n",
    "                target_type=\"categorical\",\n",
    "                progress_bar = True,\n",
    "                weight = 480,\n",
    "                method = \"mse_z\", \n",
    "                latent_group = \"reserved\",\n",
    "                counteractive_example = \"negative\",\n",
    "                transformation = \"inverse\", \n",
    "                warmup_epoch_range=warmup_epoch_range,\n",
    "                method_kwargs = {}\n",
    "            ),\n",
    "            dict(\n",
    "                apply = True, \n",
    "                target_type=\"categorical\",\n",
    "                progress_bar = True,\n",
    "                weight = 30, \n",
    "                method = \"mse_z\", \n",
    "                latent_group = \"reserved\",\n",
    "                counteractive_example = \"positive\",\n",
    "                transformation = \"none\",\n",
    "                warmup_epoch_range=warmup_epoch_range,\n",
    "                method_kwargs = {}\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs_kl_warmup = 400\n",
    "\n",
    "model_params = dict(\n",
    "    n_hidden=512,\n",
    "    n_layers=3, \n",
    "    n_latent=(8 + 24 * len(disentenglement_targets_configurations)), \n",
    "    gene_likelihood = \"nb\",\n",
    "    use_batch_norm = \"none\",\n",
    "    use_layer_norm = \"both\",\n",
    "    dropout_rate = 0.25,\n",
    "    include_auxillary_loss = True,\n",
    "    deeply_inject_disentengled_latents = False,\n",
    "    encode_covariates=False\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    max_epochs=690,\n",
    "    train_size=0.8,\n",
    "    batch_size=512,\n",
    "    check_val_every_n_epoch=10,\n",
    "    learning_rate_monitor=True,\n",
    "    # early stopping:\n",
    "    early_stopping=False,\n",
    "    early_stopping_patience=150,\n",
    "    early_stopping_monitor=\"elbo_train\",\n",
    "    plan_kwargs = dict(\n",
    "        n_epochs_kl_warmup=n_epochs_kl_warmup,\n",
    "        lr=1e-4,\n",
    "        weight_decay=1e-3,\n",
    "        # optimizer=\"AdamW\"\n",
    "        # lr-scheduler:\n",
    "        reduce_lr_on_plateau=True,\n",
    "        lr_patience=100,\n",
    "        lr_scheduler_metric=\"elbo_train\",\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset_params = dict(\n",
    "    layer=None, \n",
    "    labels_key=None,\n",
    "    batch_key=None,\n",
    "    categorical_covariate_keys=None,\n",
    "    disentenglement_targets_configurations=disentenglement_targets_configurations\n",
    ")\n",
    "\n",
    "tardis.MyModel.setup_anndata(adata, **dataset_params)\n",
    "dataset_params[\"adata_path\"] = adata_file_path\n",
    "dataset_params[\"adata\"] = os.path.split(adata_file_path)[1]\n",
    "\n",
    "tardis.MyModel.setup_wandb(\n",
    "    wandb_configurations=tardis.config.wandb,\n",
    "    hyperparams=dict(\n",
    "        model_params=model_params,\n",
    "        train_params=train_params,\n",
    "        dataset_params=dataset_params,\n",
    "    )\n",
    ")\n",
    "\n",
    "vae = tardis.MyModel(\n",
    "    adata,\n",
    "    **model_params\n",
    ")\n",
    "vae.train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join(\n",
    "    tardis.config.io_directories[\"models\"],\n",
    "    \"norman_r2_v2\"\n",
    ")\n",
    "\n",
    "vae.save(\n",
    "    dir_path,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.get_reconstruction_r2_training(top_n=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.get_MI_normalized_training(\"condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tardis._disentanglementmanager import DisentanglementManager as DM\n",
    "adata.obs[\"validation\"] = \"train\"\n",
    "adata.obs[\"validation\"].iloc[vae.validation_indices] = \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sublatent = DM.configurations.get_by_obs_key(\"condition\").reserved_latent_indices\n",
    "latent = ad.AnnData(X=vae.get_latent_representation()[:, sublatent], obs=adata.obs.copy())\n",
    "rsc.utils.anndata_to_GPU(latent)\n",
    "rsc.pp.neighbors(latent)\n",
    "rsc.tl.umap(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_colors(num_colors):\n",
    "    return [\"#\"+''.join([np.random.choice(list('0123456789ABCDEF')) for j in range(6)]) for i in range(num_colors)]\n",
    "unique_cell_types = latent.obs[\"condition\"].unique()\n",
    "# Generate random colors for each unique cell type\n",
    "random_colors = generate_random_colors(len(unique_cell_types))\n",
    "# Create a dictionary to map cell types to colors\n",
    "color_map = dict(zip(unique_cell_types, random_colors))\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sc.pl.umap(\n",
    "        latent, \n",
    "        color=[\"condition\", \"validation\"], \n",
    "        ncols=1,\n",
    "        size=8,\n",
    "        frameon=False,\n",
    "        palette=color_map,\n",
    "        legend_loc=\"on data\",\n",
    "        legend_fontsize=6,\n",
    "        legend_fontweight='bold',\n",
    "        ax=plt.gca(),\n",
    "    show=False\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sublatent = DM.configurations.unreserved_latent_indices\n",
    "latent = ad.AnnData(X=vae.get_latent_representation()[:, sublatent], obs=adata.obs.copy())\n",
    "rsc.utils.anndata_to_GPU(latent)\n",
    "rsc.pp.neighbors(latent)\n",
    "rsc.tl.umap(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    latent, \n",
    "    color=[\"condition\", \"validation\"], \n",
    "    ncols=2,\n",
    "    frameon=False,\n",
    "    legend_loc=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
